################################################################################
# This file contains the configuration for the cortex-annotate toolkit. By
# editing this file, one can configure cortex-annotate to work with various
# datasets and to enable annotation of specific contours, points, and
# boundaries. The current contents of this file configure the tool for
# annotation of the visual cortex of subjects in the NYU retinotopy dataset.

display:
  figsize: [4, 4]
  dpi: 128
  plot_options:
    color: [0.25, 0.25, 0.75]
    linewidth: 1
    markersize: 1
    linestyle: "solid"
  fg_options:
    color: [0.55, 0.55, 0.9]
    markersize: 2

init: |
  # Several code-blocks in this config.yaml file use the numpy and neuropythy
  # libraries, so we load them here.
  import numpy as np
  import neuropythy as ny

  # We also want to create an object that tracks the S3 path/data for the 
  # CHN-Retinotopy. We use the cache path "/cache/<dataset>" because the /cache
  # directory is always available for use with cache files inside of the docker
  # container that runs the annotation tool.
  dataset_path = ny.util.pseudo_path(
    source_path = "s3://openneuro.org/ds004698/derivatives", 
    cache_path  = "/cache/chn-retinotopy"
  )

  # We will specifically load these population receptive fields (pRF) files in
  # order to draw visual area annotations on the retinotopic maps for each
  # subject.
  prf_files = {
    "polar_angle"        : "angle.mgz",
    "eccentricity"       : "eccen.mgz",
    "variance_explained" : "vexpl.mgz",
  }

  # This occipital pole mask is used with neuropythy"s flatmap code; the tuple
  # indicates that the FreeSurfer parcellation property uses the value 43 to
  # indicate the occipital pole of the brain (file: *.aparc.a2009s.annot).
  occpole_mask = ( "parcellation", 43 ) 

# We assume in this example that the libraries neuropythy and numpy have been
# imported (as ny and np respectively) in the init section (see below).
targets:
  # The CHN-Retinotopy dataset contains 12 subjects, listed below. The 
  # "Subject ID" entry will be a dropdown menu in the annotation tool because it
  # is a list of multiple choices rather than a code-block or a list with a
  # single entry.
  Subject ID:
    - sub-01
    - sub-02
    - sub-03
    - sub-04
    - sub-05
    - sub-06
    - sub-07
    - sub-08
    - sub-09
    - sub-10
    - sub-11
    - sub-12
  # The "subject" entry is a multi-line string, so it is interpreted as a Python
  # code snippet. This snippet is compiled into a function whose parameter list 
  # contains only the variable `target`. The `target` will be a dictionary with
  # the target data above the subject, so in this case only the "Subject ID".
  subject: |
    # Get the subject ID that the user chose from the above selection list.
    sid = target["Subject ID"]

    # Find a sub-path for the subject"s FreeSurfer directory; we get the
    # dataset_path variable from the `init` section of the config.yaml file; 
    # see above.
    fs_path = dataset_path.subpath("freesurfer", sid)

    # Load and return a FreeSurfer subject object for this path.
    return ny.freesurfer_subject(fs_path)
  # The "Hemisphere" is a choice for the user; as a list of two options, it will
  # appear as a dropdown menu with these two options in the annotation tool.
  Hemisphere:
    - Left Hemisphere
    - Right Hemisphere
  # The "cortex" key in the target data is for the cortical surface object,
  # which is managed and loaded by neuropythy from the subject"s FreeSurfer
  # object. Note that the "cortex" entry is like the "subject" entry in that it
  # is compiled into a function whose only parameter is a dict object called
  # `target`, but because it is farther down in the target section, the `target`
  # parameter will contain entries for "Subject ID", "subject", and "Hemisphere"
  # from the sections above.
  cortex: |
    # Extract the subject ID, hemisphere name, and Subject object.
    sid  = target["Subject ID"] # string
    hemi = target["Hemisphere"] # string
    subj = target["subject"]    # Subject object

    # convert hemisphere to BIDS and freesurfer hemisphere convention
    fs_hemi   = f"{hemi[0].lower()}h"
    bids_hemi = f"{hemi[0].upper()}"

    # Load retinotopic mapping data, CHN-Retintopy specific location.
    prop_base = f"{sid}_ses-all_task-logbar_hemi-{bids_hemi}_space-fsnative"
    prop_path = dataset_path.subpath(
      "prf-estimation", sid, "prfs", f"{prop_base}_prf")
    props = {
      k: ny.load(prop_path.subpath(f"{prop_base}_{filename}"))
         for (k, filename) in prf_files.items()
    }

    # Variance Explained ----
    # CHN-Retinotopy stores the variance explained as values from 0 to 1. Here, 
    # we convert the variance explained to a percentage from 0% to 100%.
    props["variance_explained"] = props["variance_explained"] * 100
    
    # Grab the appropriate coretx/hemisphere object.
    cortex = subj.hemis[fs_hemi]
    
    # Finally, return that hemisphere object with the properties associated with
    # it (this is Neuropythy"s typical modus operandi for adding properties to
    # existing objects: make a copy with the properties attached).
    return cortex.with_prop(props)
  # Finally, we include a "flatmap" entry of the `targets` section in order to
  # create a flattened projection of the hemisphere for annotation. We use the
  # `mask_flatmap` method of the cortex/hemisphere object in order to create a
  # projection of the inflated native surface that is centered on the occipital
  # pole. This uses the `occpole_mask` defined in the `init` section above.
  flatmap: |
    cortex = target["cortex"]
    return cortex.mask_flatmap(occpole_mask, map_right = "right", radius = np.pi / 2)

annotations:
  # V1 contours:
  V1 Foveal Point:
    type: point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "variance_explained"]
  V1 UVM (ventral):
    fixed_head: V1 Foveal Point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "variance_explained"]
  V1 LVM (dorsal):
    fixed_head: V1 Foveal Point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "variance_explained"]
  V1 Periphery:
    fixed_head:
      requires: V1 UVM (ventral)
      calculate: |
        return annotations["V1 UVM (ventral)"][-1,:]
    fixed_tail:
      requires: V1 LVM (dorsal)
      calculate: |
        return annotations["V1 LVM (dorsal)"][-1,:]
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "variance_explained"]
  # V2 contours:
  V2 Foveal Point:
    type: point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "variance_explained"]
  V2 UVM (ventral):
    fixed_head: V2 Foveal Point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "variance_explained"]
  V2 LVM (dorsal):
    fixed_head: V2 Foveal Point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "variance_explained"]
  V2 Ventral Periphery:
    fixed_head:
      requires: V2 UVM (ventral)
      calculate: |
        return annotations["V2 UVM (ventral)"][-1,:]
    fixed_tail:
      requires: V1 UVM (ventral)
      calculate: |
        return annotations["V1 UVM (ventral)"][-1,:]
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "variance_explained"]
  V2 Dorsal Periphery:
    fixed_head:
      requires: V2 LVM (dorsal)
      calculate: |
        return annotations["V2 LVM (dorsal)"][-1,:]
    fixed_tail:
      requires: V1 LVM (dorsal)
      calculate: |
        return annotations["V1 LVM (dorsal)"][-1,:]
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "variance_explained"]
  # V3 contours:
  V3 Foveal Point:
    type: point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "variance_explained"]
  V3 UVM (ventral):
    fixed_head: V3 Foveal Point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "variance_explained"]
  V3 LVM (dorsal):
    fixed_head: V3 Foveal Point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "variance_explained"]
  V3 Ventral Periphery:
    fixed_head:
      requires: V3 UVM (ventral)
      calculate: |
        return annotations["V3 UVM (ventral)"][-1,:]
    fixed_tail:
      requires: V2 UVM (ventral)
      calculate: |
        return annotations["V2 UVM (ventral)"][-1,:]
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "variance_explained"]
  V3 Dorsal Periphery:
    fixed_head:
      requires: V3 LVM (dorsal)
      calculate: |
        return annotations["V3 LVM (dorsal)"][-1,:]
    fixed_tail:
      requires: V2 LVM (dorsal)
      calculate: |
        return annotations["V2 LVM (dorsal)"][-1,:]
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "variance_explained"]

figures:
  term: |
    xy = target["flatmap"].coordinates
    (xmin,ymin) = np.min(xy, axis=1)
    (xmax,ymax) = np.max(xy, axis=1)
    axes.set_xlim((xmin,xmax))
    axes.set_ylim((ymin,ymax))
  polar_angle: |
    ny.cortex_plot(target["flatmap"], color="polar_angle", axes=axes)
  eccentricity: |
    ny.cortex_plot(target["flatmap"], color="eccentricity", axes=axes)
  variance_explained: |
    ny.cortex_plot(target["flatmap"], color="variance_explained", axes=axes,
                   cmap="hot", vmin=0, vmax=100)
  curvature: |
    ny.cortex_plot(target["flatmap"], axes=axes)

review: |
  #from annotate import watershed_contours
  #im = watershed_contours(annotations.values(), max_depth=1)
  #axes.imshow(im, cmap="hsv", vmin=0, vmax=1.5*np.max(im))
  import numpy as np
  # V1:
  v1uvm = annotations["V1 UVM (ventral)"]
  v1lvm = annotations["V1 LVM (dorsal)"]
  v1per = annotations["V1 Periphery"]
  v1pol = np.vstack([v1uvm, v1per, np.flipud(v1lvm)])
  # V2:
  v2uvm = annotations["V2 UVM (ventral)"]
  v2lvm = annotations["V2 LVM (dorsal)"]
  v2pev = annotations["V2 Ventral Periphery"]
  v2ped = annotations["V2 Dorsal Periphery"]
  v2pol = np.vstack(
      [v2uvm, v2pev, np.flipud(v1uvm), v1lvm, np.flipud(v2ped), np.flipud(v2lvm)])
  # V3:
  v3uvm = annotations["V3 UVM (ventral)"]
  v3lvm = annotations["V3 LVM (dorsal)"]
  v3pev = annotations["V3 Ventral Periphery"]
  v3ped = annotations["V3 Dorsal Periphery"]
  v3pol = np.vstack(
      [v3uvm, v3pev, np.flipud(v2uvm), v2lvm, np.flipud(v3ped), np.flipud(v3lvm)])
  # Turn these into traces:
  fmap = target["flatmap"]
  v1_trace = ny.path_trace(fmap, v1pol.T, closed=True)
  v2_trace = ny.path_trace(fmap, v2pol.T, closed=True)
  v3_trace = ny.path_trace(fmap, v3pol.T, closed=True)
  # Convert the path traces into paths then into labels:
  cortex = target["cortex"]
  v1_path = v1_trace.to_path(cortex)
  v2_path = v2_trace.to_path(cortex)
  v3_path = v3_trace.to_path(cortex)
  v1 = v1_path.label > 0.5
  v2 = v2_path.label > 0.5
  v3 = v3_path.label > 0.5
  if np.sum(v1) > np.sum(~v1):
    v1 = ~v1
  if np.sum(v2) > np.sum(~v2):
    v2 = ~v2
  if np.sum(v3) > np.sum(~v3):
    v3 = ~v3
  labels = np.zeros(cortex.vertex_count, dtype=int)
  labels[v1] = 1
  labels[v2] = 2
  labels[v3] = 3
  fmap_labels = labels[fmap.labels]
  # If the user saves the contours, we want to save these labels.
  save_hooks["v123-labels.mgz"] = lambda filename: ny.save(filename, labels)
  # Plot the results:
  ny.cortex_plot(
      fmap,
      color=fmap_labels,
      cmap="rainbow",
      mask=(fmap_labels > 0),
      axes=axes,
      alpha=0.5)
  axes.axis("equal")
  axes.axis("off")

